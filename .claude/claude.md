# 立创商城爬虫系统 - Claude 开发规则

## 一、项目基本信息

**项目名称**: 立创商城爬虫系统 (LCSC Crawler System)
**技术栈**: Vue 3 + TypeScript + Spring Boot 3.1.6 + MySQL 8.0 + Redis 7
**开发语言**: Java 17 (后端) + TypeScript (前端)
**构建工具**: Maven (后端) + Vite (前端)

---

## 二、核心开发原则

### 1. 代码修改原则
- **优先编辑现有文件**,避免创建新文件
- **保持代码风格一致**,遵循项目现有代码规范
- **避免向后兼容性hack**,如重命名未使用变量、重新导出类型、添加`// removed`注释等
- **删除即删除**,如果代码未使用,直接删除而非注释
- **安全第一**,避免引入SQL注入、XSS、命令注入等OWASP Top 10漏洞

### 2. 架构原则
- **严格分层**: Controller → Service → Mapper (后端)
- **模块化设计**: 功能拆分为独立模块
- **单一职责**: 每个类/组件只负责一项功能
- **接口隔离**: 后端接口与前端API一一对应
- **依赖注入**: 使用Spring的@Autowired/@Resource

### 3. 数据库原则
- **所有表必须有主键** (通常为自增id)
- **所有表必须有created_at和updated_at字段**
- **使用MyBatis Plus的BaseMapper**,避免重复写CRUD
- **批量操作使用事务**,确保数据一致性
- **外键关系通过应用层维护**,不使用数据库外键

---

## 三、后端开发规范

### 1. Controller层规范
```java
@RestController
@RequestMapping("/api/xxx")
public class XxxController {
    @Autowired
    private XxxService xxxService;

    // 统一返回Result<T>
    @GetMapping("/list")
    public Result<PageResult<Xxx>> list(@RequestParam xxx) {
        return Result.success(xxxService.list(xxx));
    }
}
```

**规则**:
- 所有API返回`Result<T>`统一格式
- 使用RESTful风格路由
- 参数验证使用`@Valid`注解
- 异常由`GlobalExceptionHandler`统一处理

### 2. Service层规范
```java
@Service
public class XxxService {
    @Autowired
    private XxxMapper xxxMapper;

    @Transactional(rollbackFor = Exception.class)
    public void batchSave(List<Xxx> list) {
        // 批量保存逻辑
    }
}
```

**规则**:
- 复杂业务逻辑放在Service层
- 涉及多表操作使用`@Transactional`
- 批量操作使用批处理,避免循环单条插入
- Service不直接操作HTTP请求/响应

### 3. Mapper层规范
```java
@Mapper
public interface XxxMapper extends BaseMapper<Xxx> {
    // 自定义查询方法
    List<Xxx> selectByCustomCondition(@Param("xxx") String xxx);
}
```

**规则**:
- 继承`BaseMapper<T>`获取基础CRUD
- 复杂查询写在XML文件中
- 使用`@Param`注解绑定参数

### 4. Entity层规范
```java
@Data
@TableName("xxx_table")
public class Xxx {
    @TableId(type = IdType.AUTO)
    private Long id;

    private String name;

    @TableField("created_at")
    private LocalDateTime createdAt;

    @TableField("updated_at")
    private LocalDateTime updatedAt;
}
```

**规则**:
- 使用Lombok `@Data`注解
- 主键使用`@TableId(type = IdType.AUTO)`
- 字段名与数据库列名映射使用`@TableField`
- 时间字段使用`LocalDateTime`

---

## 四、前端开发规范

### 1. API调用规范
```typescript
// src/api/xxx.ts
import request from '@/utils/request';

export const getXxxList = (params: any) => {
  return request.get<PageResult<Xxx>>('/api/xxx/list', { params });
};

export const createXxx = (data: Xxx) => {
  return request.post<Xxx>('/api/xxx', data);
};
```

**规则**:
- 所有API调用封装在`api/`目录
- 使用TypeScript类型约束
- 统一使用`request`工具函数
- 接口路径与后端保持一致

### 2. 组件开发规范
```vue
<script setup lang="ts">
import { ref, onMounted } from 'vue';
import type { Xxx } from '@/types';

const dataSource = ref<Xxx[]>([]);
const loading = ref(false);

const fetchData = async () => {
  loading.value = true;
  try {
    const res = await getXxxList();
    dataSource.value = res.data;
  } catch (error) {
    message.error('加载失败');
  } finally {
    loading.value = false;
  }
};

onMounted(() => {
  fetchData();
});
</script>
```

**规则**:
- 使用`<script setup>`语法
- 响应式数据使用`ref`或`reactive`
- 异步操作使用`async/await`
- 错误处理使用`try/catch`
- 加载状态使用`loading`标识

### 3. 类型定义规范
```typescript
// src/types/index.ts
export interface Xxx {
  id?: number;
  name: string;
  createdAt?: string;
  updatedAt?: string;
}

export interface PageResult<T> {
  records: T[];
  total: number;
  size: number;
  current: number;
}
```

**规则**:
- 所有类型定义在`types/index.ts`
- 与后端实体保持一致
- 可选字段使用`?`标识
- 复用通用类型如`PageResult<T>`

---

## 五、爬虫模块开发规范

### 1. 爬虫服务目录结构
```
service/crawler/
├── core/           # 核心爬虫逻辑
├── network/        # 网络层(HTTP客户端、限流、重试)
├── parser/         # 数据解析器
├── processor/      # 数据处理器
├── error/          # 错误处理
├── memory/         # 内存优化
├── monitoring/     # 监控指标
├── scheduler/      # 任务调度
├── data/           # 批量数据处理
└── v3/             # V3版本(工作池、队列)
```

### 2. 爬虫开发原则
- **限流保护**: 所有API调用必须经过限流器
- **智能重试**: 使用`SmartRetryHandler`处理失败请求
- **批量处理**: 使用`BatchDataProcessor`批量保存数据
- **内存优化**: 大数据量使用流式处理,避免OOM
- **实时推送**: 使用WebSocket推送进度和日志
- **幂等设计**: 爬虫任务可重复执行,不产生重复数据

### 3. 爬虫配置规范
```yaml
crawler:
  delay: 2000                    # 爬取间隔(毫秒)
  timeout: 10000                 # 超时时间(毫秒)
  max-retry: 10                  # 最大重试次数
  thread-pool-size: 5            # 线程池大小
  auto-retry: true               # 自动重试
  save-images: true              # 是否保存图片
  save-pdfs: false               # 是否保存PDF(默认关闭)
```

**规则**:
- 所有配置项可在`application.yml`中调整
- 敏感操作(如删除、停止)需要确认
- 爬取间隔不低于1秒,避免被封IP

---

## 六、数据库设计规范

### 1. 表命名规范
- **小写+下划线**: `product_table`
- **复数形式**: `products`, `categories`
- **关联表**: `table1_table2` (如`product_images`)

### 2. 字段命名规范
- **主键**: `id` (BIGINT AUTO_INCREMENT)
- **外键**: `xxx_id` (如`category_id`)
- **时间戳**: `created_at`, `updated_at` (DATETIME)
- **布尔值**: `is_xxx` (TINYINT 0/1)
- **枚举值**: `xxx_status` (VARCHAR 或 TINYINT)

### 3. 索引规范
- **主键索引**: 自动创建
- **唯一索引**: 唯一约束字段(如`product_code`)
- **普通索引**: 常用查询字段(如`brand`, `category_id`)
- **联合索引**: 多字段组合查询(如`(category_id, brand)`)

### 4. 字段类型规范
| 数据类型 | 数据库类型 | 说明 |
|---------|----------|------|
| 字符串 | VARCHAR(255) | 默认长度255 |
| 长文本 | TEXT | 超过255字符 |
| 整数 | BIGINT | 主键、大数值 |
| 小整数 | INT | 普通数值 |
| 布尔值 | TINYINT | 0/1 |
| 金额 | DECIMAL(10,2) | 精确小数 |
| 时间 | DATETIME | 标准时间格式 |

---

## 七、功能开发优先级

### P0 - 核心爬虫与数据修复 (Critical / Blocker)
**优先级说明**: 直接影响数据完整性、准确性和系统稳定性,必须优先解决

1. **爬虫选区UI升级**
   - 树形结构: 一级/二级/三级折叠��构
   - 默认状态: 一级分类默认不全选

2. **爬虫选择记忆功能**
   - 记住用户上次选择的分类

3. **三级分类兼容性修复 (CRITICAL)**
   - 支持递归遍历三级分类
   - 确保无死角抓取

4. **突破5000条列表限制 (CRITICAL)**
   - 实现"筛选拆分"爬取策略
   - 通过价格区间、品牌、封装等参数切片

5. **分类名称持久化修复**
   - 数据库增加`source_name`(源名称)和`custom_name`(自定义名称)
   - 同步逻辑改为"仅更新未修改过的分类"

6. **价格阶梯扩展**
   - 从5级阶梯价扩展至6级阶梯价

7. **图片命名与逻辑重构**
   - 命名规则: `编号_图类.jpg` (如`C123456_front.jpg`)
   - 优先级: `front > blank > package > back > 无`

8. **PDF命名与开关**
   - 命名规则: `产品编号.pdf` (如`C123456789.pdf`)
   - 全局配置: `ENABLE_PDF_DOWNLOAD` (默认False)

### P1 - 新增模块与体验优化 (Major / Feature)
**优先级说明**: 在P0问题解决后,立即着手开发

1. **图片链接管理独立模块**
   - 独立CRUD页面
   - 数据模型: One-to-Many关系(一张图片 → N个店铺 → N个链接)
   - 导入功能: 支持Excel导入

### P2 - 高级导出独立模块 (Enhancement)
**优先级说明**: 增强功能,提升用户体验

1. **高级导出独立模块**
   - 独立配置页面
   - 筛选维度: 店铺选择、产品选择、价格折扣设置
   - 导出内容: 聚合数据(店铺运费模板、分类码、自定义图片链接、基础产品信息)

---

## 八、开发流程规范

### 1. 新功能开发流程
1. **需求分析**: 明确功能需求和业务逻辑
2. **数据库设计**: 设计表结构,编写SQL脚本
3. **后端开发**: Entity → Mapper → Service → Controller
4. **前端开发**: Types → API → Components → Views
5. **联调测试**: 前后端联调,修复bug
6. **代码审查**: 检查代码质量、安全性
7. **文档更新**: 更新功能列表、API文档

### 2. Bug修复流程
1. **问题定位**: 通过日志、调试定位问题
2. **根因分析**: 分析问题根本原因
3. **修复方案**: 设计修复方案
4. **代码修改**: 修改代码并测试
5. **回归测试**: 确保修复不引入新问题

### 3. 代码提交规范
```
<type>(<scope>): <subject>

<body>

<footer>
```

**Type类型**:
- `feat`: 新功能
- `fix`: Bug修复
- `refactor`: 重构
- `perf`: 性能优化
- `style`: 代码格式调整
- `docs`: 文档更新
- `test`: 测试相关
- `chore`: 构建/工具链相关

**示例**:
```
feat(crawler): 支持三级分类爬取

- 修改CategoryCrawlerService,支持递归遍历三级分类
- 更新数据库schema,添加category_level3_codes表
- 前端增加三级分类选择器组件

Closes #123
```

---

## 九、安全规范

### 1. 后端安全
- **SQL注入防护**: 使用MyBatis的`#{}`参数绑定
- **XSS防护**: 输出HTML时进行转义
- **CSRF防护**: 使用Spring Security的CSRF保护
- **权限控制**: 重要接口添加权限验证
- **敏感信息**: 密码、密钥不能硬编码,使用配置文件或环境变量

### 2. 前端安全
- **输入验证**: 所有用户输入需要验证
- **XSS防护**: 使用`v-text`而非`v-html`
- **HTTPS**: 生产环境强制使用HTTPS
- **敏感数据**: 不在localStorage存储敏感信息

### 3. 爬虫安全
- **限流保护**: 避免请求过快被封IP
- **User-Agent**: 使用合法的User-Agent
- **错误处理**: 捕获异常,避免程序崩溃
- **数据验证**: 验证爬取数据的有效性

---

## 十、性能优化规范

### 1. 后端性能优化
- **数据库优化**: 添加索引、优化SQL查询
- **缓存策略**: Redis缓存热点数据
- **批量操作**: 使用批处理减少数据库交互
- **异步处理**: 耗时操作使用异步执行
- **连接池**: 合理配置数据库连接池和HTTP连接池

### 2. 前端性能优化
- **懒加载**: 图片、组件按需加载
- **虚拟滚动**: 长列表使用虚拟滚动
- **防抖节流**: 搜索、滚动等使用防抖节流
- **代码分割**: 路由级别的代码分割
- **CDN加速**: 静态资源使用CDN

### 3. 爬虫性能优化
- **并发控制**: 合理设置线程池大小
- **批量处理**: 批量保存数据到数据库
- **内存优化**: 流式处理大数据量
- **连接复用**: HTTP连接池复用连接

---

## 十一、测试规范

### 1. 单元测试
- **覆盖率**: Service层代码覆盖率>80%
- **测试框架**: JUnit 5 + Mockito (后端), Vitest (前端)
- **Mock数据**: 使用Mock对象模拟依赖

### 2. 集成测试
- **数据库测试**: 使用H2内存数据库
- **API测试**: 使用MockMvc测试Controller
- **E2E测试**: 使用Playwright/Cypress

### 3. 爬虫测试
- **单分类测试**: 先测试单个分类爬取
- **小批量测试**: 测试批量爬取逻辑
- **异常测试**: 测试网络异常、数据异常等场景

---

## 十二、日志规范

### 1. 日志级别
- **ERROR**: 系统错误,需要立即处理
- **WARN**: 警告信息,可能存在问题
- **INFO**: 重要业务流程
- **DEBUG**: 调试信息

### 2. 日志内容
```java
// 好的日志
log.info("开始爬取分类[{}],catalogId={}", categoryName, catalogId);
log.error("爬取产品失败,productCode={}, error={}", productCode, e.getMessage(), e);

// 不好的日志
log.info("开始爬取");  // 缺少关键信息
log.error("错误");      // 没有错误上下文
```

### 3. 日志存储
- **控制台输出**: 开发环境
- **文件输出**: 生产环境,按日期切割
- **日志归档**: 保留最近30天日志

---

## 十三、文档规范

### 1. 代码注释
```java
/**
 * 爬取指定分类的产品数据
 *
 * @param catalogId 分类ID
 * @param pageSize 每页大小
 * @return 产品列表
 * @throws CrawlerException 爬取失败时抛出
 */
public List<Product> crawlProducts(String catalogId, int pageSize) {
    // 实现逻辑
}
```

### 2. API文档
- **Swagger**: 后端使用Swagger生成API文档
- **注释**: 所有公开API添加注释说明

### 3. README文档
- **项目介绍**: 项目背景、技术栈
- **快速开始**: 环境配置、启动步骤
- **功能列表**: 主要功能说明
- **开发指南**: 开发规范、目录结构

---

## 十四、监控与运维

### 1. 系统监控
- **健康检查**: `/actuator/health`端点
- **性能指标**: CPU、内存、线程池
- **业务指标**: 爬取成功率、数据量统计

### 2. 日志监控
- **错误日志**: 监控ERROR级别日志
- **慢查询**: 监控SQL慢查询
- **爬虫异常**: 监控爬虫失败率

### 3. 告警机制
- **系统告警**: CPU>80%、内存>90%
- **业务告警**: 爬取成功率<70%
- **错误告警**: ERROR日志频繁出现

---

## 十五、版本管理

### 1. 分支策略
- **master**: 生产环境分支
- **develop**: 开发分支
- **feature/xxx**: 功能分支
- **bugfix/xxx**: Bug修复分支
- **hotfix/xxx**: 紧急修复分支

### 2. 版本号规范
- **格式**: `v主版本.次版本.修订号` (如`v1.2.3`)
- **主版本**: 重大功能变更
- **次版本**: 新增功能
- **修订号**: Bug修复

### 3. 发布流程
1. 代码合并到develop分支
2. 测试通过后合并到master
3. 打tag标记版本号
4. 部署到生产环境
5. 监控系统运行状态

---

## 十六、常见问题处理

### 1. 爬虫相关
**问题**: 爬取失败率高
**解决**: 检查限流设置、网络状态、重试次数

**问题**: 数据重复
**解决**: 检查唯一索引、爬虫幂等性

**问题**: 内存溢出
**解决**: 使用批量处理、流式处理、调整JVM参数

### 2. 数据库相关
**问题**: 查询慢
**解决**: 添加索引、优化SQL、分表分库

**问题**: 连接池耗尽
**解决**: 增加连接池大小、检查连接泄漏

### 3. 前端相关
**问题**: 页面卡顿
**解决**: 虚拟滚动、懒加载、防抖节流

**��题**: 白屏
**解决**: 检查路由配置、API调用、控制台错误

---

## 十七、开发工具推荐

### 1. 后端工具
- **IDE**: IntelliJ IDEA Ultimate
- **数据库工具**: DataGrip、Navicat
- **API测试**: Postman、Apifox
- **性能分析**: JProfiler、VisualVM

### 2. 前端工具
- **IDE**: VSCode + Volar插件
- **调试工具**: Vue DevTools
- **性能分析**: Chrome DevTools
- **包管理**: pnpm (推荐)

### 3. 通用工具
- **版本管理**: Git + GitHub/GitLab
- **接口文档**: Swagger、Apifox
- **团队协作**: 飞书、钉钉
- **项目管理**: Jira、禅道

---

## 十八、学习资源

### 1. 官方文档
- **Spring Boot**: https://spring.io/projects/spring-boot
- **Vue 3**: https://cn.vuejs.org/
- **MyBatis Plus**: https://baomidou.com/
- **Ant Design Vue**: https://antdv.com/

### 2. 技术社区
- **掘金**: https://juejin.cn/
- **Stack Overflow**: https://stackoverflow.com/
- **GitHub**: https://github.com/

---

## 总结

本规则文档是立创商城爬虫系统的开发指南,涵盖了架构设计、代码规范、安全性、性能优化等方方面面。所有开发工作必须严格遵守本规则,确保代码质量和系统稳定性。

**核心原则**: 代码简洁、逻辑清晰、安全可靠、性能优异

---

## 十九、P0功能完成记录与经验总结

### ✅ 已完成功能 (2025-11-21)

#### P0-1: 爬虫选区UI升级
**状态**: ✅ 已完成

**实现内容**:
- 新增`CategoryTreeSelector.vue`组件，支持一级/二级/三级树形折叠结构
- DashboardV3.vue集成树形选择器
- 默认状态：一级分类默认不全选，避免误操作

**关键文件**:
- `lcsc-frontend/src/components/CategoryTreeSelector.vue`
- `lcsc-frontend/src/views/DashboardV3.vue`

---

#### P0-2: 爬虫选择记忆功能
**状态**: ✅ 已完成

**实现内容**:
- 使用localStorage保存用户选择的分类ID
- 页面加载时自动恢复上次选择
- 新增"清除记忆"按钮

**关键文件**:
- `lcsc-frontend/src/views/DashboardV3.vue` (STORAGE_KEY常量、handleTreeSelectionChange方法)

**⚠️ 遇到的Bug及修复**:
- **问题**: 重启后端后，之前保存的分类无法创建爬虫任务
- **根因**: 分类同步使用DELETE+INSERT导致自增ID重置，前端保存的旧ID失效
- **修复方案**:
  1. 给`catalog_id`字段添加UNIQUE索引
  2. CategorySyncService改用UPSERT模式（基于catalog_id判断是否存在）
- **教训**: **业务标识符(catalog_id)应该有唯一索引，数据同步应使用UPSERT而非DELETE+INSERT**

---

#### P0-3: 三级分类兼容性修复
**状态**: ✅ 已完成

**实现内容**:
- 数据库新增`category_level3_codes`表
- CategorySyncService支持递归解析三级分类
- CrawlerTaskQueueService智能识别分类级别（二级/三级）
- CategoryCrawlerWorkerPool支持三级分类爬取
- Product实体新增`category_level3_id`和`category_level3_name`字段
- 前端CategoryManagement.vue新增三级分类管理Tab
- ProductService.enrichCategoryNames方法支持三级分类名称填充

**关键文件**:
- `lcsc-crawler/src/main/java/com/lcsc/entity/CategoryLevel3Code.java`
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategorySyncService.java`
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CrawlerTaskQueueService.java`
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java`
- `lcsc-crawler/src/main/java/com/lcsc/entity/Product.java`
- `lcsc-frontend/src/views/CategoryManagement.vue`

**数据库变更**:
```sql
-- 新增三级分类表
CREATE TABLE category_level3_codes (...)

-- products表新增字段
ALTER TABLE products ADD COLUMN category_level3_id INT;
ALTER TABLE products ADD COLUMN category_level3_name VARCHAR(100);

-- 分类表添加catalog_id唯一索引
ALTER TABLE category_level1_codes ADD UNIQUE KEY uk_catalog_id (catalog_id);
ALTER TABLE category_level2_codes ADD UNIQUE KEY uk_catalog_id (catalog_id);
```

---

#### P0-4: 突破5000条列表限制
**状态**: ✅ 已完成

**实现内容**:
- 新增`BrandSplitUnit.java` DTO封装品牌拆分单元
- 新增`TaskSplitService.java`提供品牌拆分逻辑
  - `needSplit(int totalProducts)` - 判断是否需要拆分（阈值4800）
  - `splitByBrand(String catalogId)` - 调用API获取品牌列表并拆分
- `CrawlerTaskQueueService.java`新增`createBrandFilteredTask()`方法创建品牌筛选子任务
- `CategoryCrawlerWorkerPool.java`添加拆分检测逻辑
  - 子任务预处理：在第一次API调用前添加品牌筛选参数
  - 拆分触发：检测到totalProducts>4800时调用品牌拆分
  - 停止清理：停止爬虫时自动清理Redis残留任务
  - 自动停止：所有任务完成时自动停止爬虫
- 前端`DashboardV3.vue`显示子任务数量
  - 队列状态新增`subTaskCount`字段
  - "待处理"卡片显示"含XX个品牌子任务"
  - 进度条显示子任务提示

**关键文件**:
- `lcsc-crawler/src/main/java/com/lcsc/dto/BrandSplitUnit.java` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/TaskSplitService.java` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CrawlerTaskQueueService.java` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java` (MODIFIED)
- `lcsc-frontend/src/views/DashboardV3.vue` (MODIFIED)

**技术细节**:
- 拆分阈值：4800（保留200条buffer）
- 最大子任务数：50
- 品牌字段：优先匹配`Manufacturer`（立创API实际字段名）
- 子任务标识：`isSubTask=true`, `splitStrategy=BRAND`, `filterParams={"brandIdList":["xxx"]}`
- 任务ID格式：`TASK_{categoryId}_BRAND_{brandId}_{timestamp}`

**⚠️ 关键Bug修复**:
- 品牌字段名匹配：立创API返回`Manufacturer`而非`Brand`
- 子任务筛选参数时机：必须在第一次API调用**之前**添加，而非之后
- 停止清理残留任务：停止爬虫时等待3秒后清理Redis中的"处理中"任务

**教训**:
- **外部API字段名不可假设**：要支持多种可能的字段名（Manufacturer, Brand, manufacturer等）
- **筛选参数添加时机很关键**：子任务的筛选参数必须在构建第一次API请求前就加入
- **停止时需要清理状态**：Worker线程退出后Redis中的任务状态需要手动清理

---

#### P0-5: 分类名称持久化修复
**状态**: ✅ 已完成

**问题描述**:
- 用户手动修改的中文分类名称在系统重启后被API同步覆盖
- 例如：将"Resistor"改为"电阻"后，同步分类时又变回"Resistor"

**实现方案**:
- **数据库设计**：新增3个字段区分名称来源
  - `source_name` VARCHAR(200): API源名称（只读备份，每次同步更新）
  - `custom_name` VARCHAR(200): 用户自定义名称（手动编辑后设置）
  - `is_customized` TINYINT(1): 是否被用户修改过（0=否，1=是）
- **同步逻辑**：
  - 始终更新`source_name`（保留API原始名称作为参考）
  - 仅当`is_customized=0`时更新`categoryLevelXName`
  - 当`is_customized=1`时保留`custom_name`，不被API覆盖
- **API接口**：新增3个编辑名称端点
  - `PUT /api/categories/level1/{id}/customName`
  - `PUT /api/categories/level2/{id}/customName`
  - `PUT /api/categories/level3/{id}/customName`
- **前端UI**：
  - 自定义分类显示蓝色"自定义"标签
  - 显示API源名称（灰色小字）供参考
  - 添加"编辑名称"按钮打开编辑对话框

**关键文件**:
- `lcsc-crawler/src/main/resources/db/migration_p0-5_category_name_persistence.sql` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/entity/CategoryLevel1Code.java` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/entity/CategoryLevel2Code.java` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/entity/CategoryLevel3Code.java` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategorySyncService.java` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/controller/CategoryController.java` (MODIFIED)
- `lcsc-frontend/src/views/CategoryManagement.vue` (MODIFIED)

**数据库变更**:
```sql
-- 为三个级别的分类表添加字段
ALTER TABLE `category_level1_codes`
    ADD COLUMN `source_name` VARCHAR(200) NULL COMMENT 'API源名称（只读）',
    ADD COLUMN `custom_name` VARCHAR(200) NULL COMMENT '用户自定义名称',
    ADD COLUMN `is_customized` TINYINT(1) NOT NULL DEFAULT 0 COMMENT '是否被用户修改过';

-- 迁移现有数据
UPDATE `category_level1_codes`
SET `source_name` = `category_level1_name`, `is_customized` = 0
WHERE `source_name` IS NULL;

-- level2和level3同理
```

**核心逻辑** ([CategorySyncService.java:109-134](lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategorySyncService.java#L109-L134)):
```java
// P0-5: Always update source_name from API
level1.setSourceName(catalogName);

// Only update display name if not customized
if (level1.getIsCustomized() == null || level1.getIsCustomized() == 0) {
    level1.setCategoryLevel1Name(catalogName);  // Use API name
} else {
    // Preserve custom_name
    if (level1.getCustomName() != null && !level1.getCustomName().isEmpty()) {
        level1.setCategoryLevel1Name(level1.getCustomName());
    }
    log.debug("保持用户自定义名称: {} (源名称: {})",
        level1.getCategoryLevel1Name(), catalogName);
}
```

**前端显示** ([CategoryManagement.vue:62-74](lcsc-frontend/src/views/CategoryManagement.vue#L62-L74)):
```vue
<a-table-column title="分类名称" dataIndex="categoryLevel1Name" width="200">
  <template #default="{ record }">
    <div>
      {{ record.categoryLevel1Name }}
      <a-tag v-if="record.isCustomized === 1" color="blue">自定义</a-tag>
    </div>
    <div v-if="record.isCustomized === 1 && record.sourceName">
      API源名: {{ record.sourceName }}
    </div>
  </template>
</a-table-column>
```

**教训**:
- **区分数据来源**：外部API数据和用户自定义数据应分字段存储
- **保留原始数据**：保留API原始数据作为参考，便于用户对比
- **UI可见性**：清晰标识自定义数据，提升用户信任度

---

#### P0-6: 价格阶梯扩展（从5级到6级）
**状态**: ✅ 已完成

**需求**: 数据库及解析逻辑从支持5级阶梯价扩展至6级阶梯价

**实现方案**:
- **数据库**：新增2个字段
  - `ladder_price6_quantity` INT: 阶梯6数量
  - `ladder_price6_price` DECIMAL(10,4): 阶梯6单价（CNY）
- **后端Entity**：Product.java添加字段和getter/setter
- **爬虫解析**：processLadderPrices方法从5改为6
- **前端显示**：Tooltip显示6级、编辑表单支持6级

**关键文件**:
- `lcsc-crawler/src/main/resources/db/migration_p0-6_price_tier6.sql` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/entity/Product.java` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java` (MODIFIED)
- `lcsc-frontend/src/views/ProductManagement.vue` (MODIFIED)

**核心改动** ([CategoryCrawlerWorkerPool.java:1199](lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java#L1199)):
```java
// 从 Math.min(sorted.size(), 5) 改为 6
for (int i = 0; i < Math.min(sorted.size(), 6); i++) {
    // ...
    case 5 -> { product.setLadderPrice6Quantity(quantity); product.setLadderPrice6Price(priceValue); }
}
```

---

#### P0-7: 图片命名与逻辑重构
**状态**: ✅ 已完成

**需求**:
- 命名规则变更：从原始文件名改为 `编号_图类.jpg`（如 `C123456_front.jpg`）
- 优先级调整：`front > blank > package > back > 无`

**实现方案**:
- **新增方法**：
  - `extractImageType(filename)`: 从URL文件名提取图类（front/blank/package/back/img）
  - `generateImageFilename(productCode, originalFilename)`: 生成新文件名格式
- **优先级逻辑**：`computeImagePriority`方法调整
  - front: 0（最高）
  - blank: 1
  - package: 2
  - back: 3
  - 无标识: 4（最低）

**关键文件**:
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java` (MODIFIED)

**核心代码** ([CategoryCrawlerWorkerPool.java:1082-1137](lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java#L1082-L1137)):
```java
// 优先级计算
private int computeImagePriority(String filename) {
    String lower = filename.toLowerCase();
    if (lower.contains("_front")) { return 0; }
    if (lower.contains("_blank")) { return 1; }
    if (lower.contains("_package")) { return 2; }
    if (lower.contains("_back")) { return 3; }
    return 4;
}

// 生成新文件名
private String generateImageFilename(String productCode, String originalFilename) {
    String imageType = extractImageType(originalFilename);
    String extension = ".jpg";
    int dotIndex = originalFilename.lastIndexOf('.');
    if (dotIndex > 0) {
        extension = originalFilename.substring(dotIndex).toLowerCase();
    }
    return productCode + "_" + imageType + extension;
}
```

---

#### P0-8: PDF命名与开关
**状态**: ✅ 已完成

**需求**:
- 命名规则变更：从 `产品编号_品牌_型号.pdf` 改为 `产品编号.pdf`（如 `C123456789.pdf`）
- 功能开关：新增全局配置项 `crawler.enable-pdf-download`，默认为 `false`（暂停下载）

**实现方案**:
- **配置文件**：`application.yml` 新增 `crawler.enable-pdf-download: false`
- **后端逻辑**：
  - 添加 `@Value("${crawler.enable-pdf-download:false}")` 读取配置
  - 简化 `generatePdfFilename` 方法，只返回 `产品编号.pdf`
  - PDF下载逻辑添加开关判断，只在 `enablePdfDownload=true` 时实际下载
  - 始终保存PDF元数据（文件名、路径、URL），便于后续批量下载
- **删除代码**：移除未使用的 `cleanBrandName` 方法

**关键文件**:
- `lcsc-crawler/src/main/resources/application.yml` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java` (MODIFIED)

**核心代码** ([CategoryCrawlerWorkerPool.java:98-99, 814-839](lcsc-crawler/src/main/java/com/lcsc/service/crawler/v3/CategoryCrawlerWorkerPool.java)):
```java
// 读取配置
@Value("${crawler.enable-pdf-download:false}")
private boolean enablePdfDownload;

// PDF下载逻辑
if (pdfUrl != null && !pdfUrl.isBlank()) {
    String normalizedPdfUrl = normalizeAssetUrl(pdfUrl);

    // 生成PDF文件名（新规则：产品编号.pdf）
    String pdfFilename = generatePdfFilename(product.getProductCode());
    product.setPdfFilename(pdfFilename);
    product.setPdfLocalPath(pdfPathStr);
    product.setPdfUrl(normalizedPdfUrl);

    // 根据配置开关决定是否实际下载PDF
    if (enablePdfDownload) {
        fileDownloadService.submitDownloadTask(normalizedPdfUrl, pdfPathStr, "pdf");
        log.info("Worker 提交PDF下载任务: {} -> {}", pdfFilename, normalizedPdfUrl);
    } else {
        log.debug("Worker PDF下载已禁用，跳过下载: {}", pdfFilename);
    }
}
```

**配置使用**:
```yaml
# 默认关闭PDF下载（全站爬取阶段）
crawler:
  enable-pdf-download: false

# 全站爬取完毕后，可改为true批量下载PDF
crawler:
  enable-pdf-download: true
```

---

### 🐛 Bug修复记录

#### Bug-1: 产品图片渲染显示占位符
**问题描述**: 产品管理页面部分产品图片无法渲染，显示SVG占位符

**根因分析**:
- 数据库中`product_image_url_big`字段值为`"https:null"`
- 立创API返回的某些产品图片URL字段是字符串`"null"`
- `normalizeAssetUrl`方法未过滤这种情况，直接拼接成`"https:null"`

**修复方案**:
```java
// CategoryCrawlerWorkerPool.java - normalizeAssetUrl方法
// 过滤掉包含"null"字符串的URL
if (trimmed.equalsIgnoreCase("null") || trimmed.contains(":null")) {
    return null;
}
```

**数据修复SQL**:
```sql
UPDATE products
SET product_image_url_big = NULL, image_name = NULL
WHERE product_image_url_big LIKE '%:null%' OR product_image_url_big = 'null';
```

**教训**: **处理外部API数据时，要考虑各种边界情况，包括字符串"null"**

---

### 📝 开发经验总结

#### 1. 数据同步设计原则
- **使用UPSERT而非DELETE+INSERT**: 保持主键ID稳定，避免关联数据失效
- **业务标识符添加唯一索引**: 如`catalog_id`，便于基于业务ID查询和更新
- **区分自增ID和业务ID**: 自增ID用于内部关联，业务ID用于外部标识

#### 2. 外部API数据处理
- **字符串"null"检查**: API可能返回字符串"null"而非null对象
- **URL格式验证**: 检查URL是否有效，避免无效URL进入数据库
- **数据清洗**: 在保存前对数据进行清洗和验证

#### 3. 前端状态持久化
- **localStorage保存业务ID**: 如果保存数据库自增ID，需确保后端ID稳定
- **状态恢复验证**: 恢复状态时验证数据有效性，处理数据失效情况

#### 4. 数据库Schema变更
- **SQL脚本统一管理**: 所有变更写入`lcsc_full_schema.sql`
- **数据库操作由用户手动执行**: 避免自动执行敏感操作
- **考虑数据迁移**: 新增字段时考虑现有数据的兼容性

---

### 📋 P0功能完成情况

| 序号 | 功能 | 状态 | 备注 |
|-----|------|------|------|
| P0-1 | 爬虫选区UI升级 | ✅ 已完成 | 树形结构+默认不全选 |
| P0-2 | 爬虫选择记忆功能 | ✅ 已完成 | localStorage持久化 |
| P0-3 | 三级分类兼容性修复 | ✅ 已完成 | 递归遍历+智能任务创建 |
| P0-4 | 突破5000条列表限制 | ✅ 已完成 | 品牌拆分策略 |
| P0-5 | 分类名称持久化修复 | ✅ 已完成 | source_name + custom_name |
| P0-6 | 价格阶梯扩展(6级) | ✅ 已完成 | 数据库+解析逻辑 |
| P0-7 | 图片命名与逻辑重构 | ✅ 已完成 | 编号_图类.jpg |
| P0-8 | PDF命名与开关 | ✅ 已完成 | 产品编号.pdf + 开关配置 |

**🎉 P0级功能全部完成！**

---

## 二十、P1功能完成记录

### ✅ 已完成功能 (2025-11-21)

#### P1-1: 图片链接管理独立模块 - Excel导入功能
**状态**: ✅ 已完成

**需求描述**:
- 支持从本地Excel导入图片链接数据
- 模板格式：`[店铺名称, 产品编号, 图片名称, 图片链接]`
- 数据模型：One-to-Many关系（一张图片 → N个店铺 → N条链接）

**实现方案**:

1. **数据模型设计**:
   - 表结构：`image_links(id, image_name, shop_id, image_link, ...)`
   - 唯一约束：`UNIQUE KEY (image_name, shop_id)` - 同一图片在同一店铺只能有一条记录
   - 支持一张图片关联多个店铺，每个店铺有独立链接

2. **后端实现**:
   - **DTO类**（3个新文件）：
     - `ImageLinkImportResult.java`: 导入结果（成功数、失败数、错误列表）
     - `ImageLinkImportError.java`: 错误信息（行号、错误描述）
     - `ImageLinkImportRow.java`: Excel行数据
   - **服务层**：`ImageLinkImportService.java`
     - Excel解析（Apache POI）
     - 数据验证（必填字段、URL格式、店铺存在性）
     - 店铺名称自动转换为shopId
     - UPSERT模式保存（重复数据自动更新）
     - 模板生成功能
   - **Controller层**：新增2个API端点
     - `POST /api/image-links/import` - Excel文件导入
     - `GET /api/image-links/import-template` - 模板下载

3. **前端实现**:
   - **类型定义**：`ImageLinkImportResult`, `ImageLinkImportError`
   - **API层**：`importImageLinksFromExcel()`, `downloadImportTemplate()`
   - **UI组件**：
     - 三步骤导入流程（下载模板 → 上传文件 → 导入）
     - Upload组件支持.xlsx/.xls文件
     - 实时导入结果展示（成功/失败统计）
     - 错误详情列表（行号+错误信息）
   - **路由配置**：`/images` → `ImageManagement`
   - **菜单配置**：顶部导航添加"图片管理"菜单项

4. **表格显示优化**:
   - 固定表格布局：`table-layout="fixed"`
   - 图片链接列自动截断：`ellipsis: true`
   - 鼠标悬停显示完整链接
   - 操作列固定右侧

**关键文件**:
- `lcsc-crawler/src/main/java/com/lcsc/dto/ImageLinkImportResult.java` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/dto/ImageLinkImportError.java` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/dto/ImageLinkImportRow.java` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/service/ImageLinkImportService.java` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/controller/ImageLinkController.java` (MODIFIED)
- `lcsc-frontend/src/types/index.ts` (MODIFIED)
- `lcsc-frontend/src/api/imageLink.ts` (MODIFIED)
- `lcsc-frontend/src/views/ImageManagement.vue` (MODIFIED)
- `lcsc-frontend/src/router/index.ts` (MODIFIED)
- `lcsc-frontend/src/App.vue` (MODIFIED)

**核心代码示例**:

Excel解析逻辑 ([ImageLinkImportService.java](lcsc-crawler/src/main/java/com/lcsc/service/ImageLinkImportService.java)):
```java
@Transactional(rollbackFor = Exception.class)
public ImageLinkImportResult importFromExcel(MultipartFile file) {
    // 1. 解析Excel行数据
    // 2. 验证每行（店铺名称、图片名称、图片链接必填；URL格式验证）
    // 3. 店铺名称 → shopId 转换（缓存避免重复查询）
    // 4. UPSERT模式保存（基于唯一约束 image_name + shop_id）
    // 5. 返回导入结果（成功数、失败数、错误详情）
}
```

前端Upload组件 ([ImageManagement.vue](lcsc-frontend/src/views/ImageManagement.vue)):
```vue
<a-upload
  :file-list="uploadFileList"
  :before-upload="beforeUpload"
  accept=".xlsx,.xls"
  :max-count="1"
>
  <a-button><UploadOutlined /> 选择Excel文件</a-button>
</a-upload>
```

**数据模型验证**:
```
image_links表支持 One-to-Many 关系：
┌─────────────────────┐
│     image_name      │ 一张图片
└─────────────────────┘
           │
           ├──→ shop_id=1 → image_link_1 (店铺A的链接)
           ├──→ shop_id=2 → image_link_2 (店铺B的链接)
           └──→ shop_id=3 → image_link_3 (店铺C的链接)
```

---

### 📝 P1开发经验总结

#### 1. Excel导入最佳实践
- **模板先行**：提供下载模板功能，明确数据格式要求
- **渐进式验证**：先验证格式，再验证业务逻辑（如店铺存在性）
- **详细错误报告**：返回行号+具体错误信息，便于用户定位问题
- **UPSERT模式**：利用唯一约束实现"存在则更新，不存在则插入"

#### 2. 文件上传处理
- **前端验证**：beforeUpload中验证文件类型和大小，减少无效请求
- **阻止自动上传**：`return false` 让用户确认后手动触发上传
- **FormData传输**：MultipartFile需要使用 `Content-Type: multipart/form-data`

#### 3. 表格显示优化
- **固定布局**：`table-layout="fixed"` 防止内容撑开列宽
- **文本截断**：`ellipsis: true` + Tooltip 显示完整内容
- **固定列**：`fixed: 'right'` 确保操作列始终可见

#### 4. 路由和菜单配置
- **新页面必须添加路由**：在 `router/index.ts` 中注册
- **菜单项同步**：在 `App.vue` 中添加对应菜单项
- **图标导入**：从 `@ant-design/icons-vue` 导入对应图标

---

### 📋 P1功能完成情况

| 序号 | 功能 | 状态 | 备注 |
|-----|------|------|------|
| P1-1 | 图片链接管理Excel导入 | ✅ 已完成 | 模板下载+文件上传+错误报告 |
| P1-1a | One-to-Many数据模型 | ✅ 已完成 | 唯一约束(image_name, shop_id) |
| P1-1b | 表格显示优化 | ✅ 已完成 | 固定布局+文本截断 |

---

## 二十一、P2功能完成记录

### ✅ 已完成功能 (2025-11-21)

#### P2-1: 高级导出独立模块 - 淘宝CSV格式（批量添加模式）
**状态**: ✅ 已完成

**需求变更**:
- 从"即时筛选+Excel导出"模式改为"批量添加+淘宝CSV导出"模式
- 导出格式：从Excel改为淘宝CSV（80列固定格式）
- 操作流程：筛选 → 添加到任务列表 → 重复筛选添加 → 统一导出

**实现方案**:

**后端架构**:
- **DTO**:
  - [ExportTaskItem.java](lcsc-crawler/src/main/java/com/lcsc/dto/ExportTaskItem.java): 任务项实体（productCode, model, brand, shopId, shopName, discounts, addedAt）
  - [AdvancedExportRequest.java](lcsc-crawler/src/main/java/com/lcsc/dto/AdvancedExportRequest.java): 筛选条件（shopId单选, categoryLevel1/2/3Id, brand单选, hasImage, stockMin/Max, 6级discounts）

- **Service**: [AdvancedExportService.java](lcsc-crawler/src/main/java/com/lcsc/service/AdvancedExportService.java)
  - `addToTaskList()`: 添加产品到任务列表，按productCode去重
  - `generateTaobaoCsv()`: 生成淘宝CSV（80列），包含头部3行+数据行
  - CSV字段生成方法：
    - `buildTitle()`: "型号、封装 三级分类、二级分类、一级分类"
    - `calculatePrice()`: 最高阶价格*折扣，向上取整2位小数
    - `buildDescription()`: `<p>参数名:参数值</p>`格式
    - `buildCateProps()`: 选项编号组合（1627207:-1001; ... ;1627207:-100(N+2);）
    - `buildPicture()`: `:1:0:|`+图片链接（优先自定义链接，fallback立创原图）
    - `buildSkuProps()`: 价格1:1000000::1627207:-1001; ... （N+2级）
    - `buildPropAlias()`: 选项编号:买X-Y个选这个; ...
  - 阶梯价格辅助方法：`getLadderCount()`, `getLadderPriceByIndex()`, `getLadderQuantityByIndex()`

- **Controller**: [AdvancedExportController.java](lcsc-crawler/src/main/java/com/lcsc/controller/AdvancedExportController.java)
  - `POST /api/export/add-task`: 添加产品到任务列表
  - `POST /api/export/export-taobao-csv`: 导出任务列表为淘宝CSV

**前端架构**:
- **API**: [export.ts](lcsc-frontend/src/api/export.ts)
  - `ExportTaskItem`: 任务项类型定义
  - `AddTaskRequest`: 添加任务请求类型
  - `addToTaskList()`: 调用添加任务接口
  - `exportTaobaoCsv()`: 调用导出接口，处理CSV Blob下载

- **页面**: [AdvancedExport.vue](lcsc-frontend/src/views/AdvancedExport.vue)
  - 筛选区域：
    - 店铺单选下拉框
    - 级联分类选择（一级 → 二级 → 三级）
    - 品牌单选下拉框（支持搜索）
    - 是否有图片下拉框（全部/有图片/无图片）
    - 库存范围（最小值-最大值）
    - 6个独立折扣输入框（默认90, 88, 85, 82, 80, 78）
  - 操作按钮：确定添加、重置筛选
  - 任务列表表格：显示已添加的产品（序号、产品编号、型号、品牌、店铺、折扣配置、添加时间、操作）
  - 导出按钮：确定导出、清空列表

**淘宝CSV格式（80列）**:
```
第1行：version 1.00,Csv由Tbup理货员导出,...
第2行：英文列名（title,cid,seller_cids,stuff_status,...）
第3行：中文列名（宝贝名称,宝贝类目,店铺类目,新旧程度,...）
第4行起：产品数据
```

**关键字段说明**:
- **title**: 型号、封装 三级分类、二级分类、一级分类
- **cid**: 固定值 50018871
- **seller_cids**: 店铺二级分类码（shop.id;）
- **price**: 最高阶价格*第1级折扣，向上取整2位
- **num**: (阶梯级数+2)*1000000
- **cateProps**: 1627207:-1001;1627207:-1002;...; (N+2个选项)
- **picture**: :1:0:|+图片链接
- **skuProps**: 价格:1000000::选项编号; （N+2级，额外2级用第1阶价格）
- **propAlias**: 选项编号:买X-Y个选这个; （最后2个固定为"选数量相符的选项"和"买多少个填多少件"）

**关键文件**:
- `lcsc-crawler/src/main/java/com/lcsc/dto/ExportTaskItem.java` (NEW)
- `lcsc-crawler/src/main/java/com/lcsc/dto/AdvancedExportRequest.java` (MODIFIED)
- `lcsc-crawler/src/main/java/com/lcsc/service/AdvancedExportService.java` (REWRITTEN)
- `lcsc-crawler/src/main/java/com/lcsc/controller/AdvancedExportController.java` (REWRITTEN)
- `lcsc-frontend/src/api/export.ts` (REWRITTEN)
- `lcsc-frontend/src/views/AdvancedExport.vue` (REWRITTEN)

**核心逻辑**:

淘宝CSV头部生成 ([AdvancedExportService.java:215-226](lcsc-crawler/src/main/java/com/lcsc/service/AdvancedExportService.java#L215-L226)):
```java
private void appendCsvHeader(StringBuilder csv) {
    // 第1行：版本信息
    csv.append("version 1.00,Csv由Tbup理货员导出,");
    for (int i = 0; i < 78; i++) csv.append(",");
    csv.append("\n");

    // 第2行：英文列名
    csv.append("title,cid,seller_cids,...");

    // 第3行：中文列名
    csv.append("宝贝名称,宝贝类目,店铺类目,...");
}
```

阶梯价格N→N+2转换 ([AdvancedExportService.java:396-427](lcsc-crawler/src/main/java/com/lcsc/service/AdvancedExportService.java#L396-L427)):
```java
private String buildSkuProps(Product product, List<BigDecimal> discounts, int ladderCount) {
    int totalOptions = ladderCount + 2;

    for (int i = 0; i < totalOptions; i++) {
        BigDecimal price;
        if (i < ladderCount) {
            price = getLadderPriceByIndex(product, i + 1);  // 实际阶梯价
        } else {
            price = getLadderPriceByIndex(product, 1);  // 额外2级用第1阶价格
        }

        // 应用对应级别的折扣
        BigDecimal discount = discounts.get(Math.min(i, discounts.size() - 1))
                .divide(new BigDecimal("100"), 4, RoundingMode.HALF_UP);
        BigDecimal finalPrice = price.multiply(discount).setScale(5, RoundingMode.HALF_UP);

        props.append(finalPrice).append(":1000000::").append(OPTION_CODE_PREFIX).append(i + 1).append(";");
    }
}
```

图片链接Fallback逻辑 ([AdvancedExportService.java:374-391](lcsc-crawler/src/main/java/com/lcsc/service/AdvancedExportService.java#L374-L391)):
```java
// 优先使用自定义图片链接（image_links表）
if (product.getImageName() != null && imageLinkMap.containsKey(product.getImageName())) {
    Map<Integer, String> shopLinks = imageLinkMap.get(product.getImageName());
    if (shopLinks.containsKey(shop.getId())) {
        imageLink = shopLinks.get(shop.getId());
    }
}
// Fallback: 如果没有自定义链接，使用立创原始链接
if ((imageLink == null || imageLink.isEmpty()) && product.getProductImageUrlBig() != null) {
    imageLink = product.getProductImageUrlBig();
}
```

前端级联分类选择 ([AdvancedExport.vue:303-334](lcsc-frontend/src/views/AdvancedExport.vue#L303-L334)):
```typescript
// 一级分类变化事件
const handleLevel1Change = (value: number | undefined) => {
  filterForm.categoryLevel2Id = undefined
  filterForm.categoryLevel3Id = undefined
  level2Options.value = []
  level3Options.value = []

  if (value) {
    // 筛选二级分类
    level2Options.value = level2List.value
      .filter((cat: CategoryLevel2Code) => cat.categoryLevel1Id === value)
      .map((cat: CategoryLevel2Code) => ({
        label: cat.categoryLevel2Name,
        value: cat.id
      }))
  }
}

// 二级分类变化事件
const handleLevel2Change = (value: number | undefined) => {
  filterForm.categoryLevel3Id = undefined
  level3Options.value = []

  if (value) {
    // 筛选三级分类
    level3Options.value = level3List.value
      .filter((cat: CategoryLevel3Code) => cat.categoryLevel2Id === value)
      .map((cat: CategoryLevel3Code) => ({
        label: cat.categoryLevel3Name,
        value: cat.id
      }))
  }
}
```

**图片链接来源优先级**：
1. **优先**：`image_links` 表的自定义链接（平台专属，用户上传到各电商图床后导入）
2. **备用**：`products.product_image_url_big` 立创原始链接（爬虫已获取，无需额外操作）

---

### 📝 P2开发经验总结

#### 1. 淘宝CSV格式处理
- **固定格式**：80列固定格式，头部3行（版本信息+英文列名+中文列名）
- **CSV转义**：包含逗号、双引号或换行的字段需要用双引号包裹，内部双引号转义为两个双引号
- **字符编码**：使用UTF-8编码，确保中文正常显示
- **阶梯价格转换**：数据库N级 → 导出N+2级（额外2级使用第1阶价格）

#### 2. 批量添加模式设计
- **任务列表**：前端维护任务列表，支持多次筛选添加
- **去重逻辑**：使用LinkedHashMap按productCode去重，后添加的覆盖先添加的
- **状态管理**：任务列表保存在前端状态，刷新页面会丢失（可考虑localStorage持久化）
- **用户体验**：添加成功后提示新增数量，导出前显示总产品数

#### 3. 级联下拉框实现
- **数据加载**：页面加载时一次性获取所有三级分类数据
- **前端过滤**：根据父级ID在前端过滤子级选项，避免重复请求后端
- **状态联动**：父级变化时清空子级选中值和选项列表
- **禁用控制**：未选择父级时禁用子级下拉框，引导用户正确操作

#### 4. Blob文件下载（CSV）
- **responseType**: 请求时设置 `responseType: 'blob'`
- **MIME类型**：CSV文件使用 `text/csv;charset=utf-8`
- **文件命名**：淘宝导入_yyyyMMdd_HHmmss.csv
- **内存释放**：下载完成后调用 `URL.revokeObjectURL()` 释放内存

#### 5. 图片链接Fallback策略
- **多数据源设计**：区分"自定义链接"（image_links表）和"原始链接"（products表）
- **优先级fallback**：优先使用平台专属链接，没有则使用爬虫获取的原始链接
- **用户体验**：即使未导入自定义链接，也能看到立创原始图片
- **渐进增强**：用户可以逐步完善自定义链接，不影响现有功能

---

### 📋 P2功能完成情况

| 序号 | 功能 | 状态 | 备注 |
|-----|------|------|------|
| P2-1 | 高级导出独立模块（淘宝CSV） | ✅ 已完成 | 批量添加模式+80列CSV格式 |
| P2-1a | 批量添加工作流 | ✅ 已完成 | 筛选→添加→重复→导出 |
| P2-1b | 级联分类选择 | ✅ 已完成 | 一级→二级→三级级联下拉 |
| P2-1c | 6级折扣配置 | ✅ 已完成 | 独立输入框，默认90,88,85,82,80,78 |
| P2-1d | 淘宝CSV生成 | ✅ 已完成 | 80列固定格式，阶梯价N→N+2转换 |
| P2-1e | 图片链接Fallback | ✅ 已完成 | 优先自定义，备用立创原图 |

---

*最后更新时间: 2025-11-21*
*文档版本: v1.4*
